{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "2776efbf-9015-4f0e-8bf0-111ce43e0108",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2024-06-17 18:37:54.865243: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
                        "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
                    ]
                }
            ],
            "source": [
                "import json\n",
                "import os\n",
                "import matplotlib.pyplot as plt\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense, BatchNormalization\n",
                "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
                "from tensorflow.keras.optimizers import Adam\n",
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
                "from tensorflow.keras.applications import ResNet50\n",
                "from tensorflow.keras.regularizers import l2\n",
                "from tensorflow.keras.mixed_precision import set_global_policy\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "2e706d27-0688-4988-9a6f-2666e784735c",
            "metadata": {},
            "outputs": [],
            "source": [
                "# MIX precision training -- facilita no treino!\n",
                "set_global_policy('mixed_float16')\n",
                "\n",
                "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
                "\n",
                "# CONSTANTES\n",
                "BATCH_SIZE = 64\n",
                "IMG_SIZE = 150\n",
                "NUM_CLASSES = 10  # nº classes para identificar\n",
                "NUM_EPOCHS = 60  \n",
                "LEARNING_RATE = 0.0001  \n",
                "DENSE_LAYERS = [1024, 512, 256, 128]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "ec2b77b4-9d5f-4ed6-8f1f-38ab7d9f91d5",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Folders do dataset\n",
                "train_dirs = ['./dataset/train/train1', './dataset/train/train2',\n",
                "              './dataset/train/train3', './dataset/train/train5']\n",
                "validation_dir = './dataset/validation'\n",
                "test_dir = './dataset/test'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "1ce2b0fa-d958-482c-a087-d53f061c54bc",
            "metadata": {},
            "outputs": [
                {
                    "ename": "FileNotFoundError",
                    "evalue": "[Errno 2] No such file or directory: './dataset/train/train1'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[5], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m test_datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# training generators\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m train_generators \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mtrain_datagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mIMG_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIMG_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategorical\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_dirs\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Necessário para juntar os trainning generators and repeat\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcombined_generator\u001b[39m(generators):\n",
                        "Cell \u001b[0;32mIn[5], line 18\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m test_datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# training generators\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m train_generators \u001b[38;5;241m=\u001b[39m [\u001b[43mtrain_datagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mIMG_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIMG_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategorical\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m train_dir \u001b[38;5;129;01min\u001b[39;00m train_dirs]\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Necessário para juntar os trainning generators and repeat\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcombined_generator\u001b[39m(generators):\n",
                        "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py:1138\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow_from_directory\u001b[39m(\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1122\u001b[0m     directory,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     keep_aspect_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1137\u001b[0m ):\n\u001b[0;32m-> 1138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDirectoryIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py:453\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[1;32m    452\u001b[0m     classes \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 453\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m    454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[1;32m    455\u001b[0m             classes\u001b[38;5;241m.\u001b[39mappend(subdir)\n",
                        "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './dataset/train/train1'"
                    ]
                }
            ],
            "source": [
                "# Data Augmentation\n",
                "train_datagen = ImageDataGenerator(\n",
                "    rescale=1./255,\n",
                "    rotation_range=60,  # Increase rotation range\n",
                "    width_shift_range=0.3,  \n",
                "    height_shift_range=0.3,  \n",
                "    shear_range=0.3,  \n",
                "    zoom_range=0.3,  \n",
                "    horizontal_flip=True,\n",
                "    vertical_flip=True,  # Adicionar flip vertical\n",
                "    brightness_range=[0.6, 1.4],  # Adicionar range te brilho\n",
                "    fill_mode='nearest')\n",
                "\n",
                "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
                "test_datagen = ImageDataGenerator(rescale=1./255)\n",
                "\n",
                "# training generators\n",
                "train_generators = [train_datagen.flow_from_directory(\n",
                "    train_dir,\n",
                "    target_size=(IMG_SIZE, IMG_SIZE),\n",
                "    batch_size=BATCH_SIZE,\n",
                "    class_mode='categorical') for train_dir in train_dirs]\n",
                "\n",
                "# Necessário para juntar os trainning generators and repeat\n",
                "\n",
                "\n",
                "def combined_generator(generators):\n",
                "    while True:\n",
                "        for generator in generators:\n",
                "            for batch in generator:\n",
                "                yield batch\n",
                "\n",
                "\n",
                "train_generator = combined_generator(train_generators)\n",
                "\n",
                "# Validation e test generators\n",
                "validation_generator = validation_datagen.flow_from_directory(\n",
                "    validation_dir,\n",
                "    target_size=(IMG_SIZE, IMG_SIZE),\n",
                "    batch_size=BATCH_SIZE,\n",
                "    class_mode='categorical')\n",
                "\n",
                "test_generator = test_datagen.flow_from_directory(\n",
                "    test_dir,\n",
                "    target_size=(IMG_SIZE, IMG_SIZE),\n",
                "    batch_size=BATCH_SIZE,\n",
                "    class_mode='categorical')\n",
                "\n",
                "# Load the pre-trained ResNet50 model without the top layer and adjust input shape\n",
                "base_model = ResNet50(weights='imagenet', include_top=False,\n",
                "                      input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
                "\n",
                "# Descongelar camadas (nao meter valores demasiado altos)\n",
                "for layer in base_model.layers[-100:]:\n",
                "    layer.trainable = True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1006a450",
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras import backend as K\n",
                "from tensorflow.keras.metrics import Metric\n",
                "\n",
                "class Precision(Metric):\n",
                "    def __init__(self, name='precision', **kwargs):\n",
                "        super(Precision, self).__init__(name=name, **kwargs)\n",
                "        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
                "        self.predicted_positives = self.add_weight(name='pp', initializer='zeros')\n",
                "\n",
                "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
                "        y_pred = K.round(y_pred)\n",
                "        y_true = K.cast(y_true, 'float32')\n",
                "        self.true_positives.assign_add(K.sum(y_true * y_pred))\n",
                "        self.predicted_positives.assign_add(K.sum(y_pred))\n",
                "\n",
                "    def result(self):\n",
                "        return self.true_positives / (self.predicted_positives + K.epsilon())\n",
                "\n",
                "    def reset_states(self):\n",
                "        self.true_positives.assign(0)\n",
                "        self.predicted_positives.assign(0)\n",
                "\n",
                "class Recall(Metric):\n",
                "    def __init__(self, name='recall', **kwargs):\n",
                "        super(Recall, self).__init__(name=name, **kwargs)\n",
                "        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
                "        self.actual_positives = self.add_weight(name='ap', initializer='zeros')\n",
                "\n",
                "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
                "        y_pred = K.round(y_pred)\n",
                "        y_true = K.cast(y_true, 'float32')\n",
                "        self.true_positives.assign_add(K.sum(y_true * y_pred))\n",
                "        self.actual_positives.assign_add(K.sum(y_true))\n",
                "\n",
                "    def result(self):\n",
                "        return self.true_positives / (self.actual_positives + K.epsilon())\n",
                "\n",
                "    def reset_states(self):\n",
                "        self.true_positives.assign(0)\n",
                "        self.actual_positives.assign(0)\n",
                "\n",
                "class F1Score(Metric):\n",
                "    def __init__(self, name='f1_score', **kwargs):\n",
                "        super(F1Score, self).__init__(name=name, **kwargs)\n",
                "        self.precision = Precision()\n",
                "        self.recall = Recall()\n",
                "\n",
                "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
                "        self.precision.update_state(y_true, y_pred)\n",
                "        self.recall.update_state(y_true, y_pred)\n",
                "\n",
                "    def result(self):\n",
                "        precision = self.precision.result()\n",
                "        recall = self.recall.result()\n",
                "        return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
                "\n",
                "    def reset_states(self):\n",
                "        self.precision.reset_states()\n",
                "        self.recall.reset_states()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f6db0cfc-5d4f-45f7-952c-ad45388155cd",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Definir as layers do modelo com parametros ajustados para reduzir o overfitting\n",
                "model = Sequential([\n",
                "    base_model,\n",
                "    BatchNormalization(),\n",
                "    GlobalAveragePooling2D(),\n",
                "    # Increase model complexity\n",
                "    Dense(DENSE_LAYERS[0], activation='relu', kernel_regularizer=l2(0.03)),\n",
                "    Dropout(0.5),  # High dropout rate for regularization\n",
                "    BatchNormalization(),\n",
                "    Dense(DENSE_LAYERS[1], activation='relu', kernel_regularizer=l2(0.03)),\n",
                "    Dropout(0.5),\n",
                "    BatchNormalization(),\n",
                "    Dense(DENSE_LAYERS[2], activation='relu', kernel_regularizer=l2(0.03)),\n",
                "    Dropout(0.5),\n",
                "    Dense(DENSE_LAYERS[3], activation='relu', kernel_regularizer=l2(0.03)),\n",
                "    Dropout(0.5),\n",
                "    BatchNormalization(),\n",
                "    Dense(NUM_CLASSES, activation='softmax', dtype='float32')\n",
                "])\n",
                "\n",
                "# Compilar o modelo\n",
                "model.compile(optimizer=Adam(learning_rate=LEARNING_RATE),\n",
                "              loss='categorical_crossentropy',\n",
                "              metrics=['accuracy', Precision(), Recall(), F1Score()])\n",
                "\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "43f29c95-ca64-403a-b3d6-70d9a7f2b37c",
            "metadata": {},
            "outputs": [],
            "source": [
                "# CALLBACKS\n",
                "os.makedirs('logs', exist_ok=True)\n",
                "checkpoint = ModelCheckpoint(f'models/main_resnet50_unfreezed_100_batch_64_image_150_layers_[1024,512,256,128].keras',\n",
                "                             monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
                "early_stopping = EarlyStopping(\n",
                "    monitor='val_loss', patience=10, restore_best_weights=True)  # Increased patience\n",
                "reduce_lr = ReduceLROnPlateau(\n",
                "    monitor='val_loss', factor=0.2, patience=4, min_lr=1e-7, verbose=1)  # More aggressive schedule\n",
                "csv_logger = CSVLogger(\n",
                "    f'logs/main_resnet50_unfreezed_100_{BATCH_SIZE}_image_size_{IMG_SIZE}_layers_{DENSE_LAYERS}.csv', separator=',', append=False)\n",
                "\n",
                "# calcular passos por epoch\n",
                "steps_per_epoch = sum([gen.samples // BATCH_SIZE for gen in train_generators])\n",
                "validation_steps = validation_generator.samples // BATCH_SIZE"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a1bac321-549f-4e5f-9e2f-1da4b5aa721e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# calcular passos por epoch\n",
                "# Treinar o modelo - Nao tirar os callbacks\n",
                "history = model.fit(\n",
                "    train_generator,\n",
                "    steps_per_epoch=steps_per_epoch,\n",
                "    epochs=NUM_EPOCHS,\n",
                "    validation_data=validation_generator,\n",
                "    validation_steps=validation_steps,\n",
                "    callbacks=[checkpoint, early_stopping, reduce_lr, csv_logger]\n",
                ")\n",
                "\n",
                "# Avaliar o modelo no test generator\n",
                "# Avaliar o modelo no test generator\n",
                "results = model.evaluate(test_generator)\n",
                "loss, accuracy, precision, recall, f1_score = results[:5]\n",
                "print(f\"Test Loss: {loss}\")\n",
                "print(f\"Test Accuracy: {accuracy}\")\n",
                "print(f\"Test Precision: {precision}\")\n",
                "print(f\"Test Recall: {recall}\")\n",
                "print(f\"Test F1 Score: {f1_score}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7e0ce15d-3b9c-412d-b4fd-ecc041ac55fb",
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(12, 8))\n",
                "plt.subplot(2, 1, 1)\n",
                "plt.plot(history.history['accuracy'], label='train_accuracy')\n",
                "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
                "plt.xlabel('Epoch')\n",
                "plt.ylabel('Accuracy')\n",
                "plt.ylim([0, 1])\n",
                "plt.legend(loc='lower right')\n",
                "plt.title('Training and Validation Accuracy')\n",
                "\n",
                "plt.subplot(2, 1, 2)\n",
                "plt.plot(history.history['val_precision'], label='val_precision')\n",
                "plt.plot(history.history['val_recall'], label='val_recall')\n",
                "plt.plot(history.history['val_f1_score'], label='val_f1_score')\n",
                "plt.xlabel('Epoch')\n",
                "plt.ylabel('Metrics')\n",
                "plt.ylim([0, 1])\n",
                "plt.legend(loc='lower right')\n",
                "plt.title('Validation Precision, Recall, F1 Score')\n",
                "\n",
                "plt.savefig(f'./plots/resnet50_unfreezed_100_{BATCH_SIZE}_image_size_{IMG_SIZE}_layers_{DENSE_LAYERS}.png')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "01c78af6-c30c-4761-b015-3b5fc688b79e",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0rc1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}