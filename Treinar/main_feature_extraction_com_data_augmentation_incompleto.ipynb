{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2776efbf-9015-4f0e-8bf0-111ce43e0108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e706d27-0688-4988-9a6f-2666e784735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "# Define constants\n",
    "BATCH_SIZE = 64\n",
    "IMG_SIZE = 32\n",
    "NUM_CLASSES = 10  # Number of classes to identify\n",
    "NUM_EPOCHS = 30\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2b77b4-9d5f-4ed6-8f1f-38ab7d9f91d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "train_dirs = ['./dataset/train/train1', './dataset/train/train2', './dataset/train/train3', './dataset/train/train5']\n",
    "validation_dir = './dataset/validation'\n",
    "test_dir = './dataset/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91df877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VGG16 model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "conv_base = VGG16(weights='imagenet', include_top=False)\n",
    "conv_base.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2850e21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image data generators without augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25746f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multiple train generators\n",
    "train_generators = [train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical') for train_dir in train_dirs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88569b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom generator to merge multiple directories\n",
    "def combined_generator(generators):\n",
    "    while True:\n",
    "        for generator in generators:\n",
    "            yield next(generator)\n",
    "\n",
    "train_generator = combined_generator(train_generators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244a9268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation and test generators\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3135fa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the output of the feature extraction section for each of the datasets\n",
    "def get_features_and_labels(generator, steps):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    for i in range(steps):\n",
    "        images, labels = next(generator)\n",
    "        preprocessed_images = tf.keras.applications.vgg16.preprocess_input(images)\n",
    "        features = conv_base.predict(preprocessed_images)\n",
    "        all_features.append(features)\n",
    "        all_labels.append(labels)\n",
    "    return np.concatenate(all_features), np.concatenate(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ddd5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = sum([gen.samples // BATCH_SIZE for gen in train_generators])\n",
    "train_features, train_labels = get_features_and_labels(train_generator, steps_per_epoch)\n",
    "\n",
    "validation_steps = validation_generator.samples // BATCH_SIZE\n",
    "val_features, val_labels = get_features_and_labels(validation_generator, validation_steps)\n",
    "\n",
    "test_steps = test_generator.samples // BATCH_SIZE\n",
    "test_features, test_labels = get_features_and_labels(test_generator, test_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20541996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the new model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=train_features.shape[1:]),\n",
    "    Dense(512),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5a6e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fe8ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "checkpoint = ModelCheckpoint(\"best_model.keras\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "csv_logger = CSVLogger(f'training_log_no_aug_notpretrained_batch_size_{BATCH_SIZE}_image_size_{IMG_SIZE}.csv', append=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_features, train_labels,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(val_features, val_labels),\n",
    "    callbacks=[checkpoint, early_stopping, csv_logger]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c34f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_features, test_labels)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Plot training history\n",
    "plt.plot(history.history['accuracy'], label='train_accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
