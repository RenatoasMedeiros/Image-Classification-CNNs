{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2776efbf-9015-4f0e-8bf0-111ce43e0108",
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import tensorflow as tf\n",
                "import matplotlib.pyplot as plt\n",
                "import os\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D, BatchNormalization\n",
                "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
                "from tensorflow.keras.optimizers import Adam\n",
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2e706d27-0688-4988-9a6f-2666e784735c",
            "metadata": {},
            "outputs": [],
            "source": [
                "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
                "# Define constants\n",
                "BATCH_SIZE = 128\n",
                "IMG_SIZE = 32\n",
                "NUM_CLASSES = 10  # Number of classes to identify\n",
                "NUM_EPOCHS = 30\n",
                "LEARNING_RATE = 0.001\n",
                "DROPOUT_RATES = [0.3, 0.5, 0.5]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ec2b77b4-9d5f-4ed6-8f1f-38ab7d9f91d5",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define directories\n",
                "train_dirs = ['./dataset/train/train1', './dataset/train/train2', './dataset/train/train3', './dataset/train/train5']\n",
                "validation_dir = './dataset/validation'\n",
                "test_dir = './dataset/test'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1ce2b0fa-d958-482c-a087-d53f061c54bc",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create image data generators\n",
                "train_datagen = ImageDataGenerator(\n",
                "    rescale=1./255,\n",
                "    rotation_range=40,\n",
                "    width_shift_range=0.3,\n",
                "    height_shift_range=0.3,\n",
                "    shear_range=0.3,\n",
                "    zoom_range=0.3,\n",
                "    horizontal_flip=True,\n",
                "    fill_mode='nearest')\n",
                "\n",
                "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
                "test_datagen = ImageDataGenerator(rescale=1./255)\n",
                "\n",
                "# Create multiple train generators\n",
                "train_generators = [train_datagen.flow_from_directory(\n",
                "    train_dir,\n",
                "    target_size=(IMG_SIZE, IMG_SIZE),\n",
                "    batch_size=BATCH_SIZE,\n",
                "    class_mode='categorical') for train_dir in train_dirs]\n",
                "\n",
                "# Custom generator to merge multiple directories\n",
                "def combined_generator(generators):\n",
                "    while True:\n",
                "        for generator in generators:\n",
                "            yield next(generator)\n",
                "\n",
                "train_generator = combined_generator(train_generators)\n",
                "\n",
                "# Validation and test generators\n",
                "validation_generator = validation_datagen.flow_from_directory(\n",
                "    validation_dir,\n",
                "    target_size=(IMG_SIZE, IMG_SIZE),\n",
                "    batch_size=BATCH_SIZE,\n",
                "    class_mode='categorical')\n",
                "\n",
                "test_generator = test_datagen.flow_from_directory(\n",
                "    test_dir,\n",
                "    target_size=(IMG_SIZE, IMG_SIZE),\n",
                "    batch_size=BATCH_SIZE,\n",
                "    class_mode='categorical')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f6db0cfc-5d4f-45f7-952c-ad45388155cd",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Function to plot images\n",
                "def plot_images(images_arr):\n",
                "    fig, axes = plt.subplots(1, 10, figsize=(20,20))\n",
                "    axes = axes.flatten()\n",
                "    for img, ax in zip(images_arr, axes):\n",
                "        ax.imshow(img)\n",
                "        ax.axis('off')\n",
                "    plt.tight_layout()\n",
                "    #plt.savefig('./plot.png')\n",
                "    plt.show()\n",
                "\n",
                "# Generate a batch of images and display them\n",
                "sample_batch = next(train_generator)\n",
                "plot_images(sample_batch[0][:10])# Define the model\n",
                "model = Sequential([\n",
                "    Conv2D(128, (3, 3), input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
                "    BatchNormalization(),\n",
                "    Activation('relu'),\n",
                "    MaxPooling2D((2, 2)),\n",
                "    Dropout(DROPOUT_RATES[0]),\n",
                "    \n",
                "    Conv2D(256, (3, 3)),\n",
                "    BatchNormalization(),\n",
                "    Activation('relu'),\n",
                "    MaxPooling2D((2, 2)),\n",
                "    Dropout(DROPOUT_RATES[1]),\n",
                "    \n",
                "    Conv2D(512, (3, 3)),\n",
                "    BatchNormalization(),\n",
                "    Activation('relu'),\n",
                "    MaxPooling2D((2, 2)),\n",
                "    \n",
                "    Flatten(),\n",
                "    Dense(512),\n",
                "    BatchNormalization(),\n",
                "    Activation('relu'),\n",
                "    Dropout(DROPOUT_RATES[2]),\n",
                "    \n",
                "    Dense(NUM_CLASSES, activation='softmax')\n",
                "])\n",
                "\n",
                "# Compile the model\n",
                "model.compile(optimizer=Adam(learning_rate=LEARNING_RATE),\n",
                "              loss='categorical_crossentropy',\n",
                "              metrics=['accuracy'])\n",
                "\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "43f29c95-ca64-403a-b3d6-70d9a7f2b37c",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define callbacks\n",
                "checkpoint = ModelCheckpoint(\"best_model.keras\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
                "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
                "\n",
                "csv_logger = CSVLogger('logs/main_{BATCH_SIZE}_image_size_{IMG_SIZE}_layers_{DENSE_LAYERS}.csv', separator=',', append=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a1bac321-549f-4e5f-9e2f-1da4b5aa721e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate steps per epoch\n",
                "steps_per_epoch = sum([gen.samples // BATCH_SIZE for gen in train_generators])\n",
                "\n",
                "# Train the model\n",
                "history = model.fit(\n",
                "    train_generator,\n",
                "    steps_per_epoch=steps_per_epoch,\n",
                "    epochs=NUM_EPOCHS,\n",
                "    validation_data=validation_generator,\n",
                "    validation_steps=validation_generator.samples // BATCH_SIZE,\n",
                "    callbacks=[checkpoint, early_stopping, csv_logger]\n",
                ")\n",
                "\n",
                "# Evaluate the model\n",
                "loss, accuracy = model.evaluate(test_generator)\n",
                "print(\"Test Accuracy:\", accuracy)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7e0ce15d-3b9c-412d-b4fd-ecc041ac55fb",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save the plot of training history\n",
                "def plot_training_history(history, batch_size, output_base_dir='./plots'):\n",
                "    output_dir = f\"{output_base_dir}/batch_size_{batch_size}\"\n",
                "    if not os.path.exists(output_dir):\n",
                "        os.makedirs(output_dir)\n",
                "    plt.figure(figsize=(12, 8))\n",
                "    \n",
                "    # Plot accuracy\n",
                "    plt.subplot(2, 1, 1)\n",
                "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
                "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
                "    plt.xlabel('Epoch')\n",
                "    plt.ylabel('Accuracy')\n",
                "    plt.ylim([0, 1])\n",
                "    plt.legend(loc='lower right')\n",
                "    \n",
                "    # Plot loss\n",
                "    plt.subplot(2, 1, 2)\n",
                "    plt.plot(history.history['loss'], label='Train Loss')\n",
                "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
                "    plt.xlabel('Epoch')\n",
                "    plt.ylabel('Loss')\n",
                "    plt.ylim([0, max(history.history['loss'])])\n",
                "    plt.legend(loc='upper right')\n",
                "\n",
                "    # Add titles and text box with parameters\n",
                "    plt.suptitle('Training History', fontsize=16)\n",
                "    textstr = '\\n'.join((\n",
                "        f'Batch Size: {batch_size}',\n",
                "        f'Learning Rate: {LEARNING_RATE}',\n",
                "        f'Dropout Rates: {DROPOUT_RATES}',\n",
                "        f'Number of Layers: {len(model.layers)}',\n",
                "        f'Dense Layer: 512 units'))\n",
                "    \n",
                "    plt.gcf().text(0.15, 0.6, textstr, fontsize=12)\n",
                "    \n",
                "    # Save the plot\n",
                "    plt.tight_layout()\n",
                "    plt.savefig(os.path.join(output_dir, 'training_history.png'))\n",
                "    plt.show()\n",
                "\n",
                "# Plot and save the training history\n",
                "plot_training_history(history, BATCH_SIZE)\n",
                "\n",
                "# Evaluate the model\n",
                "loss, accuracy = model.evaluate(test_generator)\n",
                "print(\"Test Accuracy:\", accuracy)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0rc1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}