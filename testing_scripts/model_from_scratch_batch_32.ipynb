{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import os\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
                "from tensorflow.keras.optimizers import Adam\n",
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
                "from tensorflow.keras.regularizers import l2\n",
                "from tensorflow.keras.mixed_precision import set_global_policy\n",
                "\n",
                "# Enable mixed precision training\n",
                "set_global_policy('mixed_float16')\n",
                "\n",
                "\n",
                "\n",
                "# Define directories\n",
                "train_dirs = ['./dataset/train/train1', './dataset/train/train2',\n",
                "              './dataset/train/train3', './dataset/train/train5']\n",
                "validation_dir = './dataset/validation'\n",
                "test_dir = './dataset/test'"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CONSTANTES\n",
                "BATCH_SIZE = 32\n",
                "IMG_SIZE = 32\n",
                "NUM_CLASSES = 10  # nº classes para identificar\n",
                "NUM_EPOCHS = 6000  # Increase number of epochs\n",
                "LEARNING_RATE = 0.00005  # Lower learning rate for fine-tuning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Preprocessing the data\n",
                "# Create ImageDataGenerator for training, validation, and test data with only rescaling\n",
                "datagen = ImageDataGenerator(rescale=1./255)\n",
                "\n",
                "\n",
                "# training generators\n",
                "train_generators = [datagen.flow_from_directory(\n",
                "    train_dir,\n",
                "    target_size=(IMG_SIZE, IMG_SIZE),\n",
                "    batch_size=BATCH_SIZE,\n",
                "    class_mode='categorical') for train_dir in train_dirs]\n",
                "\n",
                "# Necessário para junstar os trainning generators and repeat\n",
                "def combined_generator(generators):\n",
                "    while True:\n",
                "        for generator in generators:\n",
                "            for batch in generator:\n",
                "                yield batch\n",
                "\n",
                "\n",
                "train_generator = combined_generator(train_generators)\n",
                "\n",
                "# Validation e test generators\n",
                "validation_generator = datagen.flow_from_directory(\n",
                "    validation_dir,\n",
                "    target_size=(IMG_SIZE, IMG_SIZE),\n",
                "    batch_size=BATCH_SIZE,\n",
                "    class_mode='categorical')\n",
                "\n",
                "test_generator = datagen.flow_from_directory(\n",
                "    test_dir,\n",
                "    target_size=(IMG_SIZE, IMG_SIZE),\n",
                "    batch_size=BATCH_SIZE,\n",
                "    class_mode='categorical')\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define the model\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
                "\n",
                "model = Sequential([\n",
                "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
                "    MaxPooling2D((2, 2)),\n",
                "    Dropout(0.3),\n",
                "    Conv2D(64, (3, 3), activation='relu'),\n",
                "    MaxPooling2D((2, 2)),\n",
                "    Dropout(0.3),\n",
                "    Conv2D(128, (3, 3), activation='relu'),\n",
                "    MaxPooling2D((2, 2)),\n",
                "    Flatten(),\n",
                "    Dense(512, activation='relu'),\n",
                "    Dropout(0.5),\n",
                "    Dense(NUM_CLASSES, activation='softmax')\n",
                "])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compile the model\n",
                "model.compile(optimizer=Adam(learning_rate=LEARNING_RATE),  # Reduce learning rate\n",
                "              loss='categorical_crossentropy',\n",
                "              metrics=['accuracy'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define callbacks\n",
                "os.makedirs('logs', exist_ok=True)\n",
                "checkpoint = ModelCheckpoint(\"models/best_from_scratch_{BATCH_SIZE}_image_size_{IMG_SIZE}_layers_{DENSE_LAYERS}.keras\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
                "\n",
                "early_stopping = EarlyStopping(\n",
                "    monitor='val_loss', patience=7, restore_best_weights=True) \n",
                "reduce_lr = ReduceLROnPlateau(\n",
                "    monitor='val_loss', factor=0.2, patience=2, min_lr=1e-7, verbose=1)\n",
                "\n",
                "csv_logger = CSVLogger('logs/from_scratch_training_log_{BATCH_SIZE}_image_size_{IMG_SIZE}_layers_{DENSE_LAYERS}.csv', separator=',', append=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate steps per epoch\n",
                "steps_per_epoch = sum([gen.samples // BATCH_SIZE for gen in train_generators])\n",
                "validation_steps = validation_generator.samples // BATCH_SIZE"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train the model\n",
                "history = model.fit(\n",
                "    train_generator,\n",
                "    steps_per_epoch=steps_per_epoch,\n",
                "    epochs=NUM_EPOCHS,  # Increase number of epochs\n",
                "    validation_data=validation_generator,\n",
                "    validation_steps=validation_steps,\n",
                "    callbacks=[checkpoint, early_stopping, reduce_lr, csv_logger]\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot training history and save the plot\n",
                "plt.figure()\n",
                "plt.plot(history.history['accuracy'], label='train_accuracy')\n",
                "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
                "plt.xlabel('Epoch')\n",
                "plt.ylabel('Accuracy')\n",
                "plt.ylim([0, 1])\n",
                "plt.legend(loc='lower right')\n",
                "plt.title('From scratch model Training and Validation Accuracy')\n",
                "plt.savefig('logs/from_scratch_training_accuracy_plot_{BATCH_SIZE}_image_size_{IMG_SIZE}_layers_{DENSE_LAYERS}.png')\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}